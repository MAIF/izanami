# https://www.playframework.com/documentation/latest/Configuration

play.application.loader = IzanamiLoader

play.http.secret.key = "izanamiSecret"
play.http.secret.key = ${?APPLICATION_SECRET}
http.port=9000
http.port=${?HTTP_PORT}

izanami {
  mode = "prod"
  mode = ${?IZANAMI_MODE}
  events {
    store = "InMemory"
    store = ${?IZANAMI_EVENT_STORE}
    distributed {
      topic = "izanami"
      topic = ${?DISTRIBUTED_TOPIC}
    }
    redis {
      topic = "izanami:events"
      topic = ${?REDIS_TOPIC}
    }
    kafka {
      topic = "izanami"
      topic = ${?KAFKA_TOPIC}
    }
    inmemory {}
  }
  db {
    default = "LevelDB"
    default = ${?IZANAMI_DATABASE}
    leveldb {
      parentPath = "target/leveldb"
      parentPath = ${?LEVEL_DB_PARENT_PATH}
    }
    cassandra {
      host = "localhost"
      host = ${?CASSANDRA_HOST}
      port = 9042
      port = ${?CASSANDRA_PORT}
      addresses = [${izanami.db.cassandra.host}":"${izanami.db.cassandra.port}]
      addresses = ${?CASSANDRA_HOSTS_AND_PORTS}
      replicationFactor = 1
      replicationFactor = ${?CASSANDRA_REPLICATION_FACTOR}
      keyspace = "izanami"
      keyspace = ${?CASSANDRA_KEYSPACE}
      username = ${?CASSANDRA_USERNAME}
      password = ${?CASSANDRA_PASSWORD}
    }
    redis {
      host = "localhost"
      host = ${?REDIS_HOST}
      port = 6379
      port = ${?REDIS_PORT}
      password = ${?REDIS_PASSWORD}
    }
    kafka {
      host = "127.0.0.1"
      host = ${?KAFKA_HOST}
      port = "9092"
      port = ${?KAFKA_PORT}
      servers = ${izanami.db.kafka.host}":"${izanami.db.kafka.port}
      servers = ${?KAFKA_HOSTS_AND_PORTS}
      keyPass = ${?KAFKA_PASSWORD}
      keystore {
        location = ${?KAFKA_KEYSTORE_LOCATION}
      }
      truststore {
        location = ${?KAFKA_TRUSTORE_LOCATION}
      }
    }
    elastic {
      host = "127.0.0.1"
      host = ${?ELASTIC_HOST}
      port = "9200"
      port = ${?ELASTIC_PORT}
      scheme = "http"
      scheme = ${?ELASTIC_SCHEME}
      user = ${?ELASTIC_USER}
      password = ${?ELASTIC_PASSWORD}
      automaticRefresh = false
    }
  }
  script-dispatcher {
    type = Dispatcher
    executor = "thread-pool-executor"
    thread-pool-executor {
      fixed-pool-size = 32
      fixed-pool-size = ${?SCRIPT_EXECUTION_POOLSIZE}
    }
    throughput = 1
  }
  level-db-dispatcher {
    type = Dispatcher
    executor = "thread-pool-executor"
    thread-pool-executor {
      fixed-pool-size = 1
      fixed-pool-size = ${?LEVEL_DB_POOLSIZE}
    }
    throughput = 1
  }
  filter {
    type = "Default"
    type = ${?IZANAMI_FILTER_TYPE}
    otoroshi  {
      issuer = "Otoroshi-Gateway"
      issuer = ${?OTOROSHI_ISSUER}
      sharedKey = "none"
      sharedKey = ${?CLAIM_SHAREDKEY}
      headerClaim = "Otoroshi-Gateway-Claim"
      headerClaim = ${?FILTER_CLAIM_HEADER_NAME}
      headerRequestId = "Otoroshi-Gateway-Request-Id"
      headerRequestId = ${?FILTER_REQUEST_ID_HEADER_NAME}
      headerGatewayState = "Otoroshi-Gateway-State"
      headerGatewayState = ${?FILTER_GATEWAY_STATE_HEADER_NAME}
      headerGatewayStateResp = "Otoroshi-Gateway-State-Resp"
      headerGatewayStateResp = ${?FILTER_GATEWAY_STATE_RESP_HEADER_NAME}
    }
    default {
      allowedPaths = ["/", "/login", "/api/login","/api/logout","/favicon.ico","/assets/.*","/explorer.*","/users.*", "/experiments.*", "/scripts.*", "/webhooks.*", "/configurations.*", "/features.*"]
      sharedKey = "none"
      sharedKey = ${?FILTER_CLAIM_SHAREDKEY}
      cookieClaim = "Izanami"
      cookieClaim = ${?FILTER_COOKIE_NAME}
      issuer = "Izanami"
      issuer = ${?FILTER_ISSUER}
      apiKeys {
        headerClientId = "Izanami-Client-Id"
        headerClientId = ${?FILTER_CLAIM_HEADER_CLIENT_ID_NAME}
        headerClientSecret = "Izanami-Client-Secret"
        headerClientSecret = ${?FILTER_CLAIM_HEADER_CLIENT_SECRET_NAME}
      }
    }
  }
  logout {
    url = "/api/logout"
    url = ${?LOGOUT_URL}
  }
  config {
    db {
      type = ${izanami.db.default}
      type = ${?CONFIG_DATABASE}
      conf {
        namespace = "izanami:configuration"
        namespace = ${?CONFIG_NAMESPACE}
      }
    }
  }
  features {
    db {
      type = ${izanami.db.default}
      type = ${?FEATURE_DATABASE}
      conf {
        namespace = "izanami:features"
        namespace = ${?FEATURE_NAMESPACE}
      }
    }
  }
  globalScript {
    db {
      type = ${izanami.db.default}
      type = ${?SCRIPT_DATABASE}
      conf {
        namespace = "izanami:globalscripts"
        namespace = ${?SCRIPT_NAMESPACE}
      }
    }
  }
  experiment {
    db {
      type = ${izanami.db.default}
      type = ${?EXPERIMENT_DATABASE}
      conf {
        namespace = "izanami:experiment"
        namespace = ${?EXPERIMENT_NAMESPACE}
      }
    }
  }
  variantBinding {
    db {
      type = ${izanami.db.default}
      type = ${?EXPERIMENT_VARIANT_BINDING_DATABASE}
      conf {
        namespace = "izanami:variantbinding"
        namespace = ${?EXPERIMENT_VARIANT_BINDING_NAMESPACE}
      }
    }
  }
  experimentEvent {
    db {
      type = ${izanami.db.default}
      type = ${?EXPERIMENT_EVENT_DATABASE}
      conf {
        namespace = "izanami:experimentevent"
        namespace = ${?EXPERIMENT_EVENT_NAMESPACE}
      }
    }
  }
  webhook {
    events {
      group = 20
      within = "1 second"
      nbMaxErrors = 10
      errorReset = "30 second"
    }
    ttl = "5 minutes"
    ttl = ${?WEB_HOOK_TTL}
    db {
      type = ${izanami.db.default}
      type = ${?WEBHOOK_DATABASE}
      conf {
        namespace = "izanami:webhook"
        namespace = ${?WEBHOOK_NAMESPACE}
      }
    }
  }
  user {
    db {
      type = ${izanami.db.default}
      type = ${?USER_DATABASE}
      conf {
        namespace = "izanami:user"
        namespace = ${?USER_NAMESPACE}
      }
    }
    initialize {
      userId = "admin"
      userId = ${?INITIAL_USER_ID}
      password = "admin123"
      password = ${?INITIAL_USER_PASSWORD}
    }
  }
  apikey {
    db {
      type = ${izanami.db.default}
      type = ${?APIKEY_DATABASE}
      conf {
        namespace = "izanami:apikey"
        namespace = ${?APIKEY_NAMESPACE}
      }
    }
  }

  cluster {
    seed-node-host = "127.0.0.1"
    seed-node-host = ${?AKKA_CLUSTER_SEED_NODE_HOST}
    seed-node-host = ${?IZANAMI_PORT_2551_TCP_ADDR}
    seed-node-port = 2551
    seed-node-port = ${?AKKA_CLUSTER_SEED_NODE_PORT}
    seed-node-port = ${?IZANAMI_PORT_2551_TCP_PORT}
  }
}

cluster {
  system-name = "DistributedEvent"
  akka {
    actor {
      provider = "cluster"
      provider = ${?AKKA_CLUSTER_PROVIDER}
      serializers {
        eventMessage = "domains.events.CustomSerializer"
      }
      serialization-bindings {
        "domains.events.DistributedEventsPublisherActor$Message" = eventMessage
      }
    }
    remote {
      log-remote-lifecycle-events = on
      netty.tcp {
        hostname = "127.0.0.1"
        hostname = ${?AKKA_CLUSTER_HOST}
        port = 2551
        port = ${?AKKA_CLUSTER_PORT}
        bind-hostname = "127.0.0.1" # internal (bind) hostname
        bind-hostname = ${?AKKA_CLUSTER_BIND_HOST}
        bind-port = ${cluster.akka.remote.netty.tcp.port}
        bind-port = ${?AKKA_CLUSTER_BIND_PORT}
      }
    }
    cluster {
      seed-nodes = ["akka.tcp://"${cluster.system-name}"@"${izanami.cluster.seed-node-host}":"${izanami.cluster.seed-node-port}]
      seed-nodes = ${?AKKA_CLUSTER_SEED_NODES}
    }
  }
}

# Properties for akka.kafka.ConsumerSettings can be
# defined in this section or a configuration section with
# the same layout.
akka.kafka.consumer {
  # Tuning property of scheduled polls.
  poll-interval = 50ms

  # Tuning property of the `KafkaConsumer.poll` parameter.
  # Note that non-zero value means that blocking of the thread that
  # is executing the stage will be blocked.
  poll-timeout = 50ms

  # The stage will be await outstanding offset commit requests before
  # shutting down, but if that takes longer than this timeout it will
  # stop forcefully.
  stop-timeout = 30s

  # How long to wait for `KafkaConsumer.close`
  close-timeout = 20s

  # If offset commit requests are not completed within this timeout
  # the returned Future is completed `TimeoutException`.
  commit-timeout = 15s

  # If the KafkaConsumer can't connect to the broker the poll will be
  # aborted after this timeout. The KafkaConsumerActor will throw
  # org.apache.kafka.common.errors.WakeupException which will be ignored
  # until max-wakeups limit gets exceeded.
  wakeup-timeout = 10s

  # After exceeding maxinum wakeups the consumer will stop and the stage will fail.
  max-wakeups = 10

  # Fully qualified config path which holds the dispatcher configuration
  # to be used by the KafkaConsumerActor. Some blocking may occur.
  use-dispatcher = "akka.kafka.default-dispatcher"

  # Properties defined by org.apache.kafka.clients.consumer.ConsumerConfig
  # can be defined in this configuration section.
  kafka-clients {
  }
}

akka.kafka.producer {
  # Tuning parameter of how many sends that can run in parallel.
  parallelism = 100

  # How long to wait for `KafkaProducer.close`
  close-timeout = 60s

  # Fully qualified config path which holds the dispatcher configuration
  # to be used by the producer stages. Some blocking may occur.
  # When this value is empty, the dispatcher configured for the stream
  # will be used.
  use-dispatcher = "akka.kafka.default-dispatcher"

  # Properties defined by org.apache.kafka.clients.producer.ProducerConfig
  # can be defined in this configuration section.
  kafka-clients {
  }
}
